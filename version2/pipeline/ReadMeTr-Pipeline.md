# ğŸ“Œ README - Pipeline DÃ¶kÃ¼mantasyonu  

Bu dokÃ¼man, projenin **pipeline akÄ±ÅŸÄ±nÄ±** aÃ§Ä±klayan `ReadMeTr-Pipeline.md` dosyasÄ±dÄ±r. ğŸš€

---

## ğŸ“Œ ingest.py  

Bu Python skripti, **JSON dosyasÄ±ndaki metin verilerini embedding vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rerek** yerel bir dizine kaydeder. Embedding iÅŸlemi iÃ§in **BAAI/bge-m3** modeli kullanÄ±lmaktadÄ±r.  

---

### ğŸ›  **Tercih Edilme Sebepleri**  
âœ” **Retrieve performansÄ±ndaki yÃ¼ksek baÅŸarÄ±** (MTEB leaderboard referansÄ±).  
âœ” **Hybrid search desteÄŸi** (dense ve sparse vektÃ¶rleri birlikte iÅŸleyebilir).  
âœ” **Multilingual desteÄŸi**, farklÄ± dillerde etkili performans.  
âœ” **txtai kÃ¼tÃ¼phanesi kullanÄ±larak vektÃ¶r veritabanÄ± oluÅŸturma.**  

### âš™ **KullanÄ±m**  

1. **Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:**  
   ```bash
   pip install -r requirements.txt
   ```

2. **Skripti Ã§alÄ±ÅŸtÄ±rÄ±n:**  
   ```bash
   python ingest.py
   ```

3. **Embedding vektÃ¶rleri nerede saklanÄ±r?**  
   - VektÃ¶rler **`indexes/`** klasÃ¶rÃ¼ne kaydedilir.  
   - VarsayÄ±lan olarak **`index_bge-m3_tarih`** formatÄ±nda dosya oluÅŸturulur.  
   - SQLite tabanlÄ± bir yapÄ± ile **txtai kÃ¼tÃ¼phanesi** kullanÄ±larak saklanÄ±r.  


## ğŸ“Œ query.py  

Bu Python skripti, **kullanÄ±cÄ±nÄ±n girdiÄŸi sorguya (query) embedding Ã§Ä±kararak**, daha Ã¶nce `ingest.py` skripti tarafÄ±ndan indekslenmiÅŸ vektÃ¶r veritabanÄ± Ã¼zerinde benzerlik aramasÄ± (similarity search) gerÃ§ekleÅŸtirir. **txtai kÃ¼tÃ¼phanesi** kullanÄ±larak hybrid search desteklenmektedir.  

---

### ğŸ›  **Ã–zellikler**  
âœ” **BGE-M3 embedding modeli kullanÄ±larak** sorgu embeddingâ€™leri Ã¼retilir.  
âœ” **Hybrid search desteÄŸi** (dense ve sparse vektÃ¶rlerin aÄŸÄ±rlÄ±klÄ± kombinasyonu).  
âœ” **Hybrid parametresi (alpha)** ile semantic ve syntactic aÄŸÄ±rlÄ±k dengesi ayarlanabilir.  
âœ” **Limit parametresi** ile dÃ¶ndÃ¼rÃ¼lecek dokÃ¼man sayÄ±sÄ± belirlenebilir.  
âœ” **txtai vektÃ¶r veritabanÄ± kullanÄ±larak** indekslenmiÅŸ belgelerle benzerlik aramasÄ± yapÄ±lÄ±r.  
âœ” **Sorgular interaktif olarak Ã§alÄ±ÅŸtÄ±rÄ±labilir** ve ilgili sonuÃ§lar dÃ¶ndÃ¼rÃ¼lÃ¼r.  

### âš™ **KullanÄ±m**  

1. **Skripti Ã§alÄ±ÅŸtÄ±rÄ±n:**  
   ```bash
   python query.py
   ```

2. **Parametre giriÅŸleri:**  
   - **Hybrid parametresi (alpha):** 0.0 - 0.5 arasÄ± dense (daha Ã§ok anlam), 0.5 - 1.0 arasÄ± sparse (daha Ã§ok kelime bazlÄ±) Ã¶nceliklidir.  
   - **Limit parametresi:** DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±nÄ± belirler.  
   
3. **Ã–rnek Ã‡Ä±ktÄ± FormatÄ±:**  
   ```
   Query: DijitalleÅŸme mali denetim sektÃ¶rÃ¼nÃ¼ nasÄ±l etkiliyor?
   
   File Title   : TecrÃ¼be KonuÅŸuyor - HÃ¼snÃ¼ GÃ¼reli
   Transcription: Otomasyon ve yapay zeka kullanÄ±mÄ± sayesinde...
   Score        : 0.xyzt
   ------------------------------------------------------------
   ```

---

## ğŸ“Œ query_and_llm.py

Bu Python skripti, belgelerin gÃ¶mme vektÃ¶rleri kullanÄ±larak elde edilmesi ve bu belgelerden alÄ±nan baÄŸlam ile bir BÃ¼yÃ¼k Dil Modeli (LLM) Ã¼zerinden sorgu yapÄ±lmasÄ±nÄ± saÄŸlayan bir Python skriptidir. Skript, `query.py` dosyasÄ±nÄ±n iÅŸlevini geniÅŸletmekte olup, ek olarak alÄ±nan belgeler ve sorgu birleÅŸtirilerek Llama3:70b modeline (Ollama Ã¼zerinden) iletilir.

### Temel Ã–zellikler:
- **Belge Ä°ndeksleme**: `txtai` kullanarak belgeler gÃ¶mme vektÃ¶rleriyle indekslenir ve aranÄ±r.
- **Hibrit Arama**: Ã–zelleÅŸtirilebilir aÄŸÄ±rlÄ±k parametreleriyle hibrit arama desteÄŸi.
- **LLM Entegrasyonu**: AlÄ±nan belgelerden elde edilen baÄŸlama gÃ¶re Llama3:70b modeliyle cevap Ã¼retimi.
- **BaÄŸlamsal YanÄ±t Ãœretimi**: LLM'e verilen prompt, TÃ¼rkÃ§e sistem talimatlarÄ± ve belgelerden alÄ±nan baÄŸlama gÃ¶re oluÅŸturulur.

## Gereksinimler
- Python 3.10.16
- Belge gÃ¶mme ve arama iÃ§in `txtai`
- Ollama (Llama3:70b modeli)
- `subprocess` ve `json` kÃ¼tÃ¼phaneleri (Python'da standart)

## NasÄ±l Ã‡alÄ±ÅŸÄ±r

1. **GÃ¶mme Ä°ndeksleme**:
    `EmbeddingIndexer` sÄ±nÄ±fÄ±, saÄŸlanan belgelerden bir gÃ¶mme vektÃ¶rÃ¼ indeksi oluÅŸturmak iÃ§in `txtai` kullanÄ±r. Belgeler JSON formatÄ±nda saÄŸlanÄ±r ve bu belgeler, elde edilen indeksin bir parÃ§asÄ± olarak kaydedilir. EÄŸer indeks zaten mevcutsa, bir sonraki kullanÄ±mda yÃ¼klenir.

2. **Sorgulama**:
    KullanÄ±cÄ± bir sorgu girdiÄŸinde, sistem, ilgili belgeleri gÃ¶mme vektÃ¶rleriyle arar. Elde edilen belgeler birleÅŸtirilerek baÄŸlam oluÅŸturulur.

3. **LLM Entegrasyonu**:
    Skript, elde edilen baÄŸlamÄ± ve kullanÄ±cÄ± sorgusunu Llama3:70b modeline, Ollama servisi Ã¼zerinden gÃ¶nderir. Model, baÄŸlama dayalÄ± olarak doÄŸru ve detaylÄ± bir yanÄ±t Ã¼retmesi iÃ§in yÃ¶nlendirilir.

4. **YanÄ±t Ãœretimi**:
    Model, saÄŸlanan baÄŸlama gÃ¶re kullanÄ±cÄ±nÄ±n sorgusunu yanÄ±tlamak iÃ§in bir Ã§Ä±ktÄ± Ã¼retir. Bu yanÄ±t, ekrana yazdÄ±rÄ±lÄ±r.

## Llama3:70b Modeli SeÃ§imi

`llama3:70b` modeli, bu proje iÃ§in, TÃ¼rkÃ§e dilinde doÄŸru ve anlamlÄ± yanÄ±tlar Ã¼retme konusunda yÃ¼ksek performans gÃ¶sterdiÄŸi iÃ§in seÃ§ilmiÅŸtir. GeliÅŸmiÅŸ dil modeli kapasitesi, sorgularÄ± doÄŸru ÅŸekilde anlamak ve tutarlÄ± yanÄ±tlar Ã¼retmek iÃ§in idealdir.

Ollama ile entegrasyon, model kullanÄ±mÄ±nÄ± kolaylaÅŸtÄ±rÄ±r ve yerel model altyapÄ±sÄ±nÄ±n yÃ¶netim zorluklarÄ±ndan kaÃ§Ä±nÄ±lmasÄ±nÄ± saÄŸlar, bÃ¶ylece daha verimli bir daÄŸÄ±tÄ±m saÄŸlar.

## Skript AÃ§Ä±klamasÄ±

### `EmbeddingIndexer` SÄ±nÄ±fÄ±

- **`__init__(self, model_name="BAAI/bge-m3", cuda_device="1")`**:
    Belirtilen model ve CUDA ayarlarÄ± ile indeksleme iÅŸlemine baÅŸlar.
  
- **`load_data(self, json_file)`**:
    JSON dosyasÄ±ndan belgeleri yÃ¼kler ve indekslemeye hazÄ±r hale getirir.
  
- **`prepare_documents(self)`**:
    Belgeleri, baÅŸlÄ±klar ve transkriptlerle birleÅŸtirerek indekslemeye uygun hale getirir.
  
- **`index_documents(self)`**:
    HazÄ±rlanan belgeleri `txtai` kullanarak indeksler.
  
- **`save_index(self, directory="indexes")`**:
    Ä°ndekslenen belgeleri belirtilen dizine kaydeder.

### `generate_response` Fonksiyonu

- **YanÄ±t Ãœretir**: Llama3:70b modeline, verilen baÄŸlam ve sorgu iletilerek yanÄ±t alÄ±nÄ±r. Fonksiyon, modelin sistem talimatlarÄ±na uygun bir prompt oluÅŸturur.

### Ana AkÄ±ÅŸ

1. Belgeler yÃ¼klenir veya indekslenir.
2. KullanÄ±cÄ±dan gelen sorguya gÃ¶re ilgili belgeler aranÄ±r.
3. Elde edilen belgelerden baÄŸlam oluÅŸturulur.
4. LLM'den gelen yanÄ±t, baÄŸlama dayalÄ± olarak Ã¼retilir.
5. YanÄ±t ekrana yazdÄ±rÄ±lÄ±r.

## KullanÄ±m

1. **Script'i Ã‡alÄ±ÅŸtÄ±rÄ±n**:

    ```
    python query_and_llm.py
    ```

2. **Ä°zleyin ve YanÄ±tÄ± AlÄ±n**:
    - Sorgunuzu girdikten sonra hibrit arama iÃ§in limit ve aÄŸÄ±rlÄ±k parametrelerini girin.

3. **SonuÃ§larÄ± Ä°nceleyin**:
    - Skript, en uygun belgeleri listeleyecek.
    - ArdÄ±ndan, LLM'den gelen yanÄ±tÄ± gÃ¶sterecektir.


